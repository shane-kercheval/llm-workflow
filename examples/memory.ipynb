{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is ran in a docker container where the project directory (i.e. same directory as README.md) is located in `/code`, which is set below. If you run locally you'll need to set the path of your project directory accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/code\n"
     ]
    }
   ],
   "source": [
    "%cd /code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load_dotenv` function below loads all the variables found in the `.env` file as environment variables. You must have a `.env` file located in the project directory containing your OpenAI API key, in the following format.\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=sk-...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory\n",
    "\n",
    "The default behavior of `OpenAIChat` is to add each prompt/response to/from the model to the history and use that history as the context for future prompts sent to the model (for that object's lifetime). For short conversations, this is probably ideal. For longer conversations, the number of tokens can dramatically increase, which can increase costs, and will eventually grow larger than the maximum context length allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nice to meet you, Shane! 42 is a great number, and blue is a lovely color. Is there anything specific you'd like to know or talk about?\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llm_workflow.openai import OpenAIChat\n",
    "\n",
    "chat = OpenAIChat()\n",
    "response = chat(\"Hi, my name is Shane. My favorite number is 42 and my favorite color is blue.\")\n",
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `_previous_memory` property of the `OpenAIChat` object shows the list of messages sent to the chat model for the prior interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
       " {'role': 'user',\n",
       "  'content': 'Hi, my name is Shane. My favorite number is 42 and my favorite color is blue.'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _previous_messages stores the list of messages sent to the OpenAI model.\n",
    "chat._previous_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your favorite number is 42.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat(\"What is my favorite number?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
       " {'role': 'user',\n",
       "  'content': 'Hi, my name is Shane. My favorite number is 42 and my favorite color is blue.'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Nice to meet you, Shane! 42 is a great number, and blue is a lovely color. Is there anything specific you'd like to know or talk about?\"},\n",
       " {'role': 'user', 'content': 'What is my favorite number?'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat._previous_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your favorite color is blue.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat(\"What is my favorite color?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
       " {'role': 'user',\n",
       "  'content': 'Hi, my name is Shane. My favorite number is 42 and my favorite color is blue.'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Nice to meet you, Shane! 42 is a great number, and blue is a lovely color. Is there anything specific you'd like to know or talk about?\"},\n",
       " {'role': 'user', 'content': 'What is my favorite number?'},\n",
       " {'role': 'assistant', 'content': 'Your favorite number is 42.'},\n",
       " {'role': 'user', 'content': 'What is my favorite color?'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat._previous_messages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LastNExchangesManager"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The `OpenAIChat` model has a `memory_manager` parameter and takes a `MemoryManager` class. A `MemoryManager` class is a callable that takes a `list[ExchangeRecord]` (i.e. from the `model.history()` property) and also returns a `list[ExchangeRecord]` serving as the model's memory (i.e. a list containing the messages that will be sent to the model along with the new prompt). This allows the end user to easily define a memory strategy of their own (e.g. keep the first message and the last `n` messages).\n",
    "\n",
    "One Example of a `MemoryManager` is a `LastNExchangesManager` class where you can specify the last `n` messages that you want to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nice to meet you, Shane! 42 is a great number, and blue is a lovely color. Is there anything specific you'd like to talk about or ask?\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llm_workflow.openai import OpenAIChat\n",
    "from llm_workflow.memory import LastNExchangesManager\n",
    "\n",
    "# only remember the last message (i.e. prompt/response)\n",
    "chat = OpenAIChat(memory_manager=LastNExchangesManager(last_n_exchanges=1))\n",
    "response = chat(\"Hi, my name is Shane. My favorite number is 42 and my favorite color is blue.\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
       " {'role': 'user',\n",
       "  'content': 'Hi, my name is Shane. My favorite number is 42 and my favorite color is blue.'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat._previous_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your favorite number is 42.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat(\"What is my favorite number?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
       " {'role': 'user',\n",
       "  'content': 'Hi, my name is Shane. My favorite number is 42 and my favorite color is blue.'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Nice to meet you, Shane! 42 is a great number, and blue is a lovely color. Is there anything specific you'd like to talk about or ask?\"},\n",
       " {'role': 'user', 'content': 'What is my favorite number?'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat._previous_messages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are only keeping the last message (i.e. the last prompt/response), the model will not have access to my name or favorite color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I don't have that information. Can you please tell me your favorite color?\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat(\"What is my favorite color?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
       " {'role': 'user', 'content': 'What is my favorite number?'},\n",
       " {'role': 'assistant', 'content': 'Your favorite number is 42.'},\n",
       " {'role': 'user', 'content': 'What is my favorite color?'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat._previous_messages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
