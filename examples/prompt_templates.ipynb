{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_helpers import mprint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Templates\n",
    "\n",
    "A prompt-template is just a way to build different prompts to send to a chat model, based on pre-defined use-cases."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DocSearchTemplate\n",
    "\n",
    "A document search template is an object that searches a `DocumentIndex` based on a query, and inserts `n_docs` documents into the prompt, along with additional wording to the model asking it to use the information provided from the docs to answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_workflow.indexes import ChromaDocumentIndex\n",
    "from llm_workflow.prompt_templates import DocSearchTemplate\n",
    "\n",
    "doc_index = ChromaDocumentIndex()\n",
    "prompt_template = DocSearchTemplate(doc_index=doc_index, n_docs=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the default prompt-template used by `DocSearchTemplate`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Answer the question at the end of the text as truthfully and accurately as possible, based on the following information provided.\n",
       "\n",
       "Here is the information:\n",
       "\n",
       "```\n",
       "{{documents}}\n",
       "```\n",
       "\n",
       "Here is the question:\n",
       "\n",
       "```\n",
       "{{prompt}}\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mprint(prompt_template.template)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add documents to our document index.\n",
    "\n",
    "**If we pass a list of documents to `doc_index`, the `__call__` method will pass the list to the `add()` method. If we pass a string or Document to `dock_index`, the `__call__` method will pass the value to the `search()` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_workflow.base import Document\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        content=\"The greatest basketball player of all time is Michael Jordan\",\n",
    "        metadata={'id': 1}\n",
    "    ),\n",
    "    Document(\n",
    "        content=\"The greatest three point shooter of all time is Steph Curry.\",\n",
    "        metadata={'id': 0}\n",
    "    ),\n",
    "    Document(\n",
    "        content=\"The greatest hockey player of all time is Wayne Gretzky.\",\n",
    "        metadata={'id': 2}\n",
    "    ),\n",
    "]\n",
    "# passing list[Document] is equivalent of calling `doc_index.add(docs)`\n",
    "doc_index(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(content='The greatest three point shooter of all time is Steph Curry.', metadata={'id': 0, 'distance': 0.35710838437080383})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# passing a string (or Document) is equivalent of calling `doc_index.search(value)`\n",
    "doc_index(\"Who is the greatest 3-point shooter of all time?\", n_results=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's construct our prompt. The `DocSearchTemplate` object will retrieve the most relevant document (from the `ChromaDocumentIndex` object) based on the value we send it, and then inject that document into the prompt. Because we set `n_docs=1` above, it will only include one Document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Answer the question at the end of the text as truthfully and accurately as possible, based on the following information provided.\n",
       "\n",
       "Here is the information:\n",
       "\n",
       "```\n",
       "The greatest three point shooter of all time is Steph Curry.\n",
       "```\n",
       "\n",
       "Here is the question:\n",
       "\n",
       "```\n",
       "Who is the greatest 3-point shooter of all time?\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = prompt_template(\"Who is the greatest 3-point shooter of all time?\")\n",
    "mprint(prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PythonObjectMetadataTemplate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To create a graph using plotly express of checking account balance and the duration of the loan, you can use the `plotly.express` library in Python. You can use the `scatter` function to create a scatter plot with the checking account balance on the x-axis and the duration of the loan on the y-axis.\n",
       "\n",
       "Here's an example of how you can achieve this:\n",
       "\n",
       "```python\n",
       "import plotly.express as px\n",
       "\n",
       "# Assuming my_credit_df is the DataFrame containing the data\n",
       "fig = px.scatter(my_credit_df, x='checking_balance', y='months_loan_duration', title='Checking Account Balance vs. Loan Duration')\n",
       "fig.show()\n",
       "```\n",
       "\n",
       "This code will create a scatter plot with the checking account balance on the x-axis and the duration of the loan on the y-axis, using the data from the `my_credit_df` DataFrame."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llm_workflow.base import Workflow\n",
    "from llm_workflow.openai import OpenAIChat\n",
    "from llm_workflow.prompt_templates import PythonObjectMetadataTemplate, MetadataMetadata\n",
    "import pandas as pd\n",
    "from notebook_helpers import mprint\n",
    "\n",
    "my_credit_df = pd.read_csv('/code/tests/test_data/data/credit.csv')\n",
    "\n",
    "workflow = Workflow(tasks=[\n",
    "    PythonObjectMetadataTemplate(metadatas=[\n",
    "        MetadataMetadata(obj=my_credit_df, object_name='my_credit_df'),\n",
    "    ]),\n",
    "    OpenAIChat(),\n",
    "])\n",
    "\n",
    "response = workflow(\"Create a graph using plotly express of checking account balance and the duration of the loan.?\")\n",
    "mprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Answer the question at the end of the text as truthfully and accurately as possible. Use the metadata of the python objects as appropriate. Tailor your response according to the most relevant objects. Don't use the if they don't appear relevant.\n",
       "\n",
       "Here is the metadata:\n",
       "\n",
       "```\n",
       "A pd.DataFrame `my_credit_df` that contains the following columns with the following types of values:\n",
       "\n",
       "`checking_balance`: [<class 'str'>]\n",
       "`months_loan_duration`: [<class 'int'>]\n",
       "`credit_history`: [<class 'str'>]\n",
       "`purpose`: [<class 'str'>]\n",
       "`amount`: [<class 'int'>]\n",
       "`savings_balance`: [<class 'str'>]\n",
       "`employment_duration`: [<class 'str'>]\n",
       "`percent_of_income`: [<class 'int'>]\n",
       "`years_at_residence`: [<class 'int'>]\n",
       "`age`: [<class 'int'>]\n",
       "`other_credit`: [<class 'str'>]\n",
       "`housing`: [<class 'str'>]\n",
       "`existing_loans_count`: [<class 'int'>]\n",
       "`job`: [<class 'str'>]\n",
       "`dependents`: [<class 'int'>]\n",
       "`phone`: [<class 'str'>]\n",
       "`default`: [<class 'str'>]\n",
       "\n",
       "The following numeric columns contain the following summary statistics:\n",
       "\n",
       "                       count      mean          std  ...     50%      75%      max\n",
       "months_loan_duration  1000.0    20.903    12.058814  ...    18.0    24.00     72.0\n",
       "amount                1000.0  3271.258  2822.736876  ...  2319.5  3972.25  18424.0\n",
       "percent_of_income     1000.0     2.973     1.118715  ...     3.0     4.00      4.0\n",
       "years_at_residence    1000.0     2.845     1.103718  ...     3.0     4.00      4.0\n",
       "age                   1000.0    35.546    11.375469  ...    33.0    42.00     75.0\n",
       "existing_loans_count  1000.0     1.407     0.577654  ...     1.0     2.00      4.0\n",
       "dependents            1000.0     1.155     0.362086  ...     1.0     1.00      2.0\n",
       "\n",
       "[7 rows x 8 columns]\n",
       "\n",
       "The following non-numeric columns contain the following unique values and corresponding value counts:\n",
       "\n",
       "`checking_balance`: {'unknown': 394, '< 0 DM': 274, '1 - 200 DM': 269, '> 200 DM': 63}\n",
       "`credit_history`: {'good': 530, 'critical': 293, 'poor': 88, 'very good': 49, 'perfect': 40}\n",
       "`purpose`: {'furniture/appliances': 473, 'car': 337, 'business': 97, 'education': 59, 'renovations': 22, 'car0': 12}\n",
       "`savings_balance`: {'< 100 DM': 603, 'unknown': 183, '100 - 500 DM': 103, '500 - 1000 DM': 63, '> 1000 DM': 48}\n",
       "`employment_duration`: {'1 - 4 years': 339, '> 7 years': 253, '4 - 7 years': 174, '< 1 year': 172, 'unemployed': 62}\n",
       "`other_credit`: {'none': 814, 'bank': 139, 'store': 47}\n",
       "`housing`: {'own': 713, 'rent': 179, 'other': 108}\n",
       "`job`: {'skilled': 630, 'unskilled': 200, 'management': 148, 'unemployed': 22}\n",
       "`phone`: {'no': 596, 'yes': 404}\n",
       "`default`: {'no': 700, 'yes': 300}\n",
       "\n",
       "```\n",
       "\n",
       "----\n",
       "\n",
       "Here is the question:\n",
       "\n",
       "```\n",
       "Create a graph using plotly express of checking account balance and the duration of the loan.?\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mprint(workflow.history()[0].prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the metadata provided, the columns that are likely to be the best predictors of `default` are `checking_balance`, `credit_history`, `purpose`, `savings_balance`, `employment_duration`, `other_credit`, `housing`, `job`, and `phone`.\n",
       "\n",
       "Here's the code for logistic regression using statsmodels to analyze the predictors of `default`:\n",
       "\n",
       "```python\n",
       "import pandas as pd\n",
       "import statsmodels.api as sm\n",
       "from sklearn.preprocessing import OneHotEncoder\n",
       "\n",
       "# One hot encode non-numeric columns\n",
       "non_numeric_columns = ['checking_balance', 'credit_history', 'purpose', 'savings_balance', 'employment_duration', 'other_credit', 'housing', 'job', 'phone']\n",
       "encoded_df = pd.get_dummies(my_credit_df, columns=non_numeric_columns, drop_first=True)\n",
       "\n",
       "# Define the independent variables (predictors) and the dependent variable\n",
       "X = encoded_df.drop('default', axis=1)\n",
       "y = encoded_df['default']\n",
       "\n",
       "# Add a constant to the independent variables\n",
       "X = sm.add_constant(X)\n",
       "\n",
       "# Fit logistic regression model\n",
       "logit_model = sm.Logit(y, X)\n",
       "result = logit_model.fit()\n",
       "\n",
       "# Print the summary of coefficients\n",
       "print(result.summary())\n",
       "```\n",
       "\n",
       "This code will perform logistic regression using statsmodels, one hot encode the non-numeric columns, and print the summary of coefficients for the logistic regression model."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llm_workflow.base import Workflow\n",
    "from llm_workflow.openai import OpenAIChat\n",
    "from llm_workflow.prompt_templates import PythonObjectMetadataTemplate, MetadataMetadata\n",
    "import pandas as pd\n",
    "from notebook_helpers import mprint\n",
    "\n",
    "my_credit_df = pd.read_csv('/code/tests/test_data/data/credit.csv')\n",
    "\n",
    "workflow = Workflow(tasks=[\n",
    "    PythonObjectMetadataTemplate(metadatas=[\n",
    "        MetadataMetadata(obj=my_credit_df, object_name='my_credit_df'),\n",
    "    ]),\n",
    "    OpenAIChat(),\n",
    "])\n",
    "\n",
    "response = workflow(\"Which columns are going to be the best predictors of `default`? Show me the code for logistic regression using statsmode. One hot encode any non-numeric columns and print the summary of coefficients.\")\n",
    "mprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
