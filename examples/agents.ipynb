{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is ran in a docker container where the project directory (i.e. same directory as README.md) is located in `/code`, which is set below. If you run locally you'll need to set the path of your project directory accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/code\n"
     ]
    }
   ],
   "source": [
    "%cd /code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load_dotenv` function below loads all the variables found in the `.env` file as environment variables. You must have a `.env` file located in the project directory containing your OpenAI API key, in the following format.\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=sk-...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from notebook_helpers import usage_string, mprint\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAIFunctionAgent\n",
    "\n",
    "The `OpenAIFunctionAgent` is a wrapper around OpenAI `functions`: https://platform.openai.com/docs/guides/gpt/function-calling\n",
    "\n",
    "It decides which tool to use based on the question; it then uses (i.e. calls) that tool (each tool is a callable) and returns the corresponding result. If no tool is used, it returns `None`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Tools"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to define two tools, `fake_weather_api` and `fake_stock_api`.\n",
    "\n",
    "The `OpenAIFunctionAgent` object will decide which tool to use (i.e. each tool is a callable) and it will return the corresponding response, or `None` if no tool is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_workflow.agents import OpenAIFunctionAgent, tool\n",
    "\n",
    "@tool(\n",
    "    name=\"ask_weather\",\n",
    "    description=\"Use this function to answer questions about the weather for a particular city.\",  # noqa\n",
    "    inputs={\n",
    "        'location': {\n",
    "            'type': 'string',\n",
    "            'description': \"The city and state, e.g. San Francisco, CA\",\n",
    "        },\n",
    "        'unit': {\n",
    "                'type': 'string',\n",
    "                'enum': ['celsius', 'fahrenheit'],\n",
    "                'description': \"The temperature unit to use. The model needs to infer this from the `location`.\",  # noqa\n",
    "        },\n",
    "    },\n",
    "    required= ['location', 'unit'],\n",
    ")\n",
    "def fake_weather_api(location: str, unit: str) -> str:\n",
    "    return f\"The temperature of {location} is 1000 degrees {unit}.\"\n",
    "\n",
    "@tool(\n",
    "    name=\"ask_stock_price\",\n",
    "    description=\"Use this function to answer questions about the the stock price for a particular stock symbol.\",  # noqa\n",
    "    inputs={\n",
    "        'symbol': {\n",
    "            'type': 'string',\n",
    "            'description': \"The stock symbol, e.g. 'AAPL'\",\n",
    "        },\n",
    "    },\n",
    "    required= ['symbol'],\n",
    ")\n",
    "def fake_stock_api(symbol: str) -> str:\n",
    "        return f\"The stock price of {symbol} is $1000.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define/Run Agent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define and run our Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The temperature of Seattle, WA is 1000 degrees celsius.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = OpenAIFunctionAgent(\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    tools=[fake_weather_api, fake_stock_api],\n",
    ")\n",
    "\n",
    "agent(\"What is the temperature in Seattle WA.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost:              $0.00032\n",
      "Total Tokens:       204\n",
      "Prompt Tokens:      179\n",
      "Response Tokens:    25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(usage_string(agent))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The stock price of AAPL is $1000.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"What is the stock price of Apple?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost:              $0.00062\n",
      "Total Tokens:       400\n",
      "Prompt Tokens:      358\n",
      "Response Tokens:    42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(usage_string(agent))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "agent(\"Unknow.\") is None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `history()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ExchangeRecord(uuid='8301a582-c58b-4cc1-b38b-d57f3765af02', timestamp='2023-10-01 02:22:51.227', metadata={'model_name': 'gpt-3.5-turbo', 'tool_name': 'ask_weather', 'tool_args': {'location': 'Seattle, WA', 'unit': 'celsius'}}, cost=0.0003185, total_tokens=204, prompt='What is the temperature in Seattle WA.', response=\"tool: 'ask_weather' - {'location': 'Seattle, WA', 'unit': 'celsius'}\", input_tokens=179, response_tokensns=25),\n",
       " ExchangeRecord(uuid='53732108-6113-46c8-95f7-05b36f95cbaf', timestamp='2023-10-01 02:22:53.146', metadata={'model_name': 'gpt-3.5-turbo', 'tool_name': 'ask_stock_price', 'tool_args': {'symbol': 'AAPL'}}, cost=0.00030250000000000003, total_tokens=196, prompt='What is the stock price of Apple?', response=\"tool: 'ask_stock_price' - {'symbol': 'AAPL'}\", input_tokens=179, response_tokensns=17),\n",
       " ExchangeRecord(uuid='e8d7c49e-401d-4eb1-a0a3-714cef2602fd', timestamp='2023-10-01 02:22:53.788', metadata={'model_name': 'gpt-3.5-turbo'}, cost=0.00031099999999999997, total_tokens=199, prompt='Unknow.', response='', input_tokens=174, response_tokensns=25)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.history()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the function call and arguments in the `metadata` of the `ExchangeRecord`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'gpt-3.5-turbo',\n",
       " 'tool_name': 'ask_weather',\n",
       " 'tool_args': {'location': 'Seattle, WA', 'unit': 'celsius'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.history()[0].metadata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
